import streamlit as st

import pandas as pd

import duckdb

import requests

import re

import io

from PIL import Image



# ---- CONFIG ---- #

API_KEY = "sk-153c4decdf4e4a79995c685af7fad5c8"

API_URL = "https://api.deepseek.com/v1/chat/completions"

ENCODINGS = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252', 'utf-16', 'utf-32']

st.set_page_config(page_title="Lead Intelligence for Almo Media", layout="wide")



# ---- Load Almo Media Logo ---- #

try:

Â  Â  almo_logo = Image.open("logo.jpg")

except FileNotFoundError:

Â  Â  almo_logo = None

Â  Â  st.warning("âš ï¸ Almo Media logo not found at the specified path.")



# ---- Custom Header with Logo and Branding (Larger Logo) ---- #

st.markdown(

Â  Â  """

Â  Â  <style>

Â  Â  Â  Â  .header-container {

Â  Â  Â  Â  Â  Â  display: flex;

Â  Â  Â  Â  Â  Â  flex-direction: column; /* Arrange logo and text vertically */

Â  Â  Â  Â  Â  Â  align-items: flex-start; /* Align items to the left */

Â  Â  Â  Â  Â  Â  padding-bottom: 1rem;

Â  Â  Â  Â  Â  Â  border-bottom: 1px solid #eee;

Â  Â  Â  Â  Â  Â  margin-bottom: 1.5rem;

Â  Â  Â  Â  }

Â  Â  Â  Â  .logo-container {

Â  Â  Â  Â  Â  Â  margin-bottom: 0.5rem; /* Space between logo and subtitle */

Â  Â  Â  Â  }

Â  Â  Â  Â  .logo-img {

Â  Â  Â  Â  Â  Â  max-height: none; /* Remove max-height to allow larger scaling */

Â  Â  Â  Â  Â  Â  width: 300px; /* Increased width for a larger logo */

Â  Â  Â  Â  }

Â  Â  Â  Â  .sub-title {

Â  Â  Â  Â  Â  Â  font-size: 16px !important; /* Slightly smaller subtitle */

Â  Â  Â  Â  Â  Â  line-height: 1.4; /* Improved readability */

Â  Â  Â  Â  Â  Â  text-align: left !important; /* Ensure left alignment */

Â  Â  Â  Â  }

Â  Â  Â  Â  .block-container {

Â  Â  Â  Â  Â  Â  padding-top: 2rem;

Â  Â  Â  Â  }

Â  Â  Â  Â  .st-expander {

Â  Â  Â  Â  Â  Â  border: 1px solid #ddd;

Â  Â  Â  Â  Â  Â  border-radius: 5px;

Â  Â  Â  Â  Â  Â  margin-bottom: 0.5rem;

Â  Â  Â  Â  }

Â  Â  Â  Â  .st-metric {

Â  Â  Â  Â  Â  Â  padding: 15px;

Â  Â  Â  Â  Â  Â  border-radius: 5px;

Â  Â  Â  Â  Â  Â  background-color: #f9f9f9;

Â  Â  Â  Â  Â  Â  box-shadow: 0 1px 3px rgba(0,0,0,0.05);

Â  Â  Â  Â  }

Â  Â  Â  Â  .stDownloadButton {

Â  Â  Â  Â  Â  Â  background-color: #0F52BA !important;

Â  Â  Â  Â  Â  Â  color: white !important;

Â  Â  Â  Â  Â  Â  font-weight: bold !important;

Â  Â  Â  Â  Â  Â  border-radius: 5px !important;

Â  Â  Â  Â  Â  Â  padding: 10px 20px !important;

Â  Â  Â  Â  Â  Â  box-shadow: 0 1px 3px rgba(0,0,0,0.1);

Â  Â  Â  Â  Â  Â  transition: background-color 0.3s ease;

Â  Â  Â  Â  }

Â  Â  Â  Â  .stDownloadButton:hover {

Â  Â  Â  Â  Â  Â  background-color: #0A3D80 !important;

Â  Â  Â  Â  }

Â  Â  Â  Â  .stTextInput > div > div > input {

Â  Â  Â  Â  Â  Â  border-radius: 5px;

Â  Â  Â  Â  Â  Â  border: 1px solid #ccc;

Â  Â  Â  Â  Â  Â  padding: 10px;

Â  Â  Â  Â  }

Â  Â  Â  Â  .horizontal-columns {

Â  Â  Â  Â  Â  Â  display: flex;

Â  Â  Â  Â  Â  Â  flex-wrap: wrap;

Â  Â  Â  Â  Â  Â  gap: 5px; /* Adjust gap as needed */

Â  Â  Â  Â  }

Â  Â  Â  Â  .column-name {

Â  Â  Â  Â  Â  Â  font-size: 0.9em;

Â  Â  Â  Â  }

Â  Â  </style>

Â  Â  """,

Â  Â  unsafe_allow_html=True,

)



with st.container():

Â  Â  st.markdown('<div class="header-container">', unsafe_allow_html=True)

Â  Â  if almo_logo:

Â  Â  Â  Â  st.image(almo_logo, use_container_width=False, width=300) # Increased width

Â  Â  st.markdown('<div class="sub-title">Unlock valuable insights from your lead data to drive strategic decisions. Powered by Yugensys Software.</div>', unsafe_allow_html=True)

Â  Â  st.markdown('</div>', unsafe_allow_html=True)



st.divider()



# ---- File Reader with Encoding Handling (Encoding Hidden) ---- #

def read_file_with_encoding(uploaded_file):

Â  Â  content = uploaded_file.read()

Â  Â  uploaded_file.seek(0)



Â  Â  if uploaded_file.name.endswith(".csv"):

Â  Â  Â  Â  for encoding in ENCODINGS:

Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  decoded = content.decode(encoding)

Â  Â  Â  Â  Â  Â  Â  Â  df = pd.read_csv(io.StringIO(decoded))

Â  Â  Â  Â  Â  Â  Â  Â  return df

Â  Â  Â  Â  Â  Â  except Exception:

Â  Â  Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  raise ValueError("âŒ Unable to decode the CSV file with supported encodings.")



Â  Â  elif uploaded_file.name.endswith((".xls", ".xlsx")):

Â  Â  Â  Â  return pd.read_excel(uploaded_file)



Â  Â  else:

Â  Â  Â  Â  raise ValueError("âŒ Unsupported file format.")



# ---- Upload File Section ---- #

st.subheader("ğŸ“¤ Upload Your Lead Data")

uploaded_file = st.file_uploader("Drag and drop your CSV or Excel file here", type=["csv", "xls", "xlsx"])



if uploaded_file:

Â  Â  try:

Â  Â  Â  Â  df = read_file_with_encoding(uploaded_file)

Â  Â  Â  Â  st.success("âœ… File successfully loaded.") # Removed encoding information

Â  Â  except Exception as e:

Â  Â  Â  Â  st.error(f"âš ï¸ Error loading file: {str(e)}")

Â  Â  Â  Â  st.stop()



Â  Â  # ---- Data Processing and Feature Engineering (No Changes Here) ---- #

Â  Â  def clean_numeric_column(col):

Â  Â  Â  Â  col = col.astype(str).str.replace(r"[\$,]", "", regex=True).str.lower()

Â  Â  Â  Â  def convert(val):

Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  val = val.strip()

Â  Â  Â  Â  Â  Â  Â  Â  if 'billion' in val: return float(re.findall(r'[0-9.]+', val)[0]) * 1e9

Â  Â  Â  Â  Â  Â  Â  Â  elif 'million' in val: return float(re.findall(r'[0-9.]+', val)[0]) * 1e6

Â  Â  Â  Â  Â  Â  Â  Â  elif 'thousand' in val: return float(re.findall(r'[0-9.]+', val)[0]) * 1e3

Â  Â  Â  Â  Â  Â  Â  Â  elif 'b' in val: return float(val.replace('b', '')) * 1e9

Â  Â  Â  Â  Â  Â  Â  Â  elif 'm' in val: return float(val.replace('m', '')) * 1e6

Â  Â  Â  Â  Â  Â  Â  Â  elif 'k' in val: return float(val.replace('k', '')) * 1e3

Â  Â  Â  Â  Â  Â  Â  Â  return float(val)

Â  Â  Â  Â  Â  Â  except:

Â  Â  Â  Â  Â  Â  Â  Â  return None

Â  Â  Â  Â  return col.apply(convert)



Â  Â  for col in df.columns:

Â  Â  Â  Â  if df[col].dtype == 'object':

Â  Â  Â  Â  Â  Â  sample = df[col].dropna().astype(str).str.lower()

Â  Â  Â  Â  Â  Â  if sample.str.contains(r'\d', regex=True).any():

Â  Â  Â  Â  Â  Â  Â  Â  converted = clean_numeric_column(df[col])

Â  Â  Â  Â  Â  Â  Â  Â  df[col] = converted.fillna(df[col])

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  df[col] = df[col].fillna("Unknown")

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  df[col] = df[col].fillna(df[col].median())



Â  Â  def extract_min_emp_size(size_str):

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  size_str = str(size_str).replace(",", "").strip()

Â  Â  Â  Â  Â  Â  if '+' in size_str: return int(re.findall(r'\d+', size_str)[0])

Â  Â  Â  Â  Â  Â  elif '-' in size_str: return int(size_str.split('-')[0])

Â  Â  Â  Â  Â  Â  else: return int(size_str)

Â  Â  Â  Â  except:

Â  Â  Â  Â  Â  Â  return None



Â  Â  emp_columns = ["Employee Size range", "LinkedIn Emp Size", "Headcount", "Size"]

Â  Â  fallback_columns = ["Revenue Size", "Annual Revenue"]



Â  Â  emp_size_col = next((col for col in emp_columns if col in df.columns), None)

Â  Â  fallback_col = next((col for col in fallback_columns if col in df.columns), None)



Â  Â  if emp_size_col:

Â  Â  Â  Â  df["Emp Size Num"] = df[emp_size_col].apply(extract_min_emp_size)

Â  Â  elif fallback_col:

Â  Â  Â  Â  df["Emp Size Num"] = df[fallback_col]



Â  Â  if "Revenue Size" in df.columns:

Â  Â  Â  Â  df["Revenue Size"] = clean_numeric_column(df["Revenue Size"])



Â  Â  try:

Â  Â  Â  Â  duckdb.unregister("leads")

Â  Â  except:

Â  Â  Â  Â  pass

Â  Â  duckdb.register("leads", df)



Â  Â  st.success("âœ… Data processing complete.")



Â  Â  # ---- Data Overview Metrics (Styled) ---- #

Â  Â  st.subheader("ğŸ“Š Data Overview")

Â  Â  col1, col2, col3 = st.columns(3)

Â  Â  with col1:

Â  Â  Â  Â  st.metric("Total Leads", f"{len(df):,}")

Â  Â  with col2:

Â  Â  Â  Â  st.metric("Number of Attributes", len(df.columns))

Â  Â  with col3:

Â  Â  Â  Â  st.metric("Numeric Attributes", df.select_dtypes(include='number').shape[1])



Â  Â  # ---- Optional Data Exploration (Styled Expanders) ---- #

Â  Â  with st.expander("ğŸ” Explore Sample Data"):

Â  Â  Â  Â  st.dataframe(df.head(10), use_container_width=True)



Â  Â  with st.expander("ğŸ“Œ View All Column Names"):

Â  Â  Â  Â  column_names_text = ", ".join(df.columns)

Â  Â  Â  Â  st.markdown(f"<div style='font-size: 0.9em; white-space: pre-wrap;'>{column_names_text}</div>", unsafe_allow_html=True)



Â  Â  # ---- Querying Section (Styled Input) ---- #

Â  Â  st.subheader("ğŸ§  Ask Questions About Your Leads")

Â  Â  user_query = st.text_input("Enter your question here (e.g., 'Show me leads from companies with more than 50 employees')", "")



Â  Â  if user_query:

Â  Â  Â  Â  def query_deepseek(user_query, table_name, df):

Â  Â  Â  Â  Â  Â  schema_description = "\n".join([f'- "{col}" ({str(dtype)})' for col, dtype in zip(df.columns, df.dtypes)])

Â  Â  Â  Â  Â  Â  sample_rows = df.head(5).to_dict(orient="records")



Â  Â  Â  Â  Â  Â  system_prompt = f"""You are a smart SQL assistant that converts natural language into precise SQL queries for DuckDB.



### CONTEXT:

You will be working with a table named: leads

This table is loaded from a CSV/XLS file, so column types may vary (e.g., dates as strings, numbers with symbols, or missing values).

The user may not know exact column names or data types, so your job is to interpret intent and output valid SQL.



### RULES FOR WRITING SQL:

- Always use only the table name: leads

- Wrap all column names in **double quotes**

- Do NOT guess column names â€” only use those provided

- Ensure SQL is compatible with DuckDB syntax



### COLUMN METADATA:

Below are the column names and their data types:

{schema_description}



### SAMPLE ROWS:

These are example rows to understand context and content:

{sample_rows}



### SPECIAL HANDLING RULES:

1. If a column contains ranges like "1001-5000" or "10,001+", use the "Emp Size Num" column (if present) for numeric filtering.

2. If employee size is missing, but revenue exists, assume "Emp Size Num" may have been inferred from "Revenue Size".

3. For partial text matches (like job titles or industries), use:

Â  Â  - `ILIKE '%keyword%'`

4. For boolean-like values (e.g. "is verified", "has funding"):

Â  Â  - Match values like 'yes', 'true', or 1

5. If comparing values in **string columns** with:

Â  Â  - **Dates**: CAST to TIMESTAMP â†’ `CAST("Last Funding Date" AS TIMESTAMP)`

Â  Â  - **Numbers**: CAST to DOUBLE â†’ `CAST("Revenue Size" AS DOUBLE)`

6. When comparing dates like "last 60 days":

Â  Â  - Use: `CAST("Last Funding Date" AS TIMESTAMP) >= CURRENT_DATE - INTERVAL '60 days'`

7. Always ensure correct casting before numeric or timestamp comparisons.

8. Always handle missing/null values gracefully using `IS NOT NULL` where needed.

9. Combine multiple conditions with AND/OR using parentheses properly.

10. If the user uses general terms like "revenue", "employee size", or "headcount", map them to the actual column names:

Â  Â  - "revenue" â†’ "Revenue Size"

Â  Â  - "employee size", "headcount" â†’ "Emp Size Num"

Â  Â  - "employees", "staff count" â†’ "Emp Size Num"

Â  Â  - "annual revenue", "total revenue" â†’ "Revenue Size"

Â  Â  - These mappings should be used only if the actual column exists in the provided schema.



### OUTPUT FORMAT:

Respond with only the valid SQL query (no markdown, no extra text, no explanations)."""



Â  Â  Â  Â  Â  Â  headers = {

Â  Â  Â  Â  Â  Â  Â  Â  "Authorization": f"Bearer {API_KEY}",

Â  Â  Â  Â  Â  Â  Â  Â  "Content-Type": "application/json",

Â  Â  Â  Â  Â  Â  }



Â  Â  Â  Â  Â  Â  payload = {

Â  Â  Â  Â  Â  Â  Â  Â  "model": "deepseek-chat",

Â  Â  Â  Â  Â  Â  Â  Â  "messages": [

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {"role": "system", "content": system_prompt},

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {"role": "user", "content": user_query}

Â  Â  Â  Â  Â  Â  Â  Â  ],

Â  Â  Â  Â  Â  Â  Â  Â  "temperature": 0.3

Â  Â  Â  Â  Â  Â  }



Â  Â  Â  Â  Â  Â  response = requests.post(API_URL, headers=headers, json=payload)



Â  Â  Â  Â  Â  Â  if response.status_code != 200:

Â  Â  Â  Â  Â  Â  Â  Â  raise Exception(f"DeepSeek API Error: {response.text}")



Â  Â  Â  Â  Â  Â  raw_sql = response.json()["choices"][0]["message"]["content"].strip()

Â  Â  Â  Â  Â  Â  cleaned_sql = raw_sql.replace("```sql", "").replace("```", "").strip()

Â  Â  Â  Â  Â  Â  return cleaned_sql



Â  Â  Â  Â  with st.spinner("ğŸ” Processing your query..."):

Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  sql_query = query_deepseek(user_query, "leads", df)

Â  Â  Â  Â  Â  Â  Â  Â  result_df = duckdb.sql(sql_query).df()



Â  Â  Â  Â  Â  Â  Â  Â  if not result_df.empty:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"âœ… Found {len(result_df):,} matching leads.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(result_df, use_container_width=True)



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  csv = result_df.to_csv(index=False).encode("utf-8")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.download_button(

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label="ğŸ“¥ Download Query Results as CSV",

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data=csv,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_name="almo_media_lead_query_results.csv",

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mime="text/csv",

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("No leads found matching your criteria.")



Â  Â  Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  Â  Â  st.error("âš ï¸ Sorry, an error occurred while processing your query.")

Â  Â  Â  Â  Â  Â  Â  Â  st.caption(str(e))



else:

Â  Â  st.info("ğŸ“‚ Please upload a CSV or Excel file to begin analyzing your lead data.")



# ---- Footer ---- #

st.markdown("---")

st.markdown(

Â  Â  '<p style="text-align: center; color: #888;">Powered by <a href="https://www.yugensys.com/" target="_blank" style="color: #0F52BA;">Yugensys Software</a></p>',

Â  Â  unsafe_allow_html=True,

)
